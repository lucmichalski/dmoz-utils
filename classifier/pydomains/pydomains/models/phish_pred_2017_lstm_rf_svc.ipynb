{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Phish URL</th>\n",
       "      <th>Submitted</th>\n",
       "      <th>Valid?</th>\n",
       "      <th>Online?</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4717300</td>\n",
       "      <td>http://g28.ycxafz.biz/added on Jan 1st 2017 6:...</td>\n",
       "      <td>by cleanmx</td>\n",
       "      <td>VALID PHISH</td>\n",
       "      <td>Offline</td>\n",
       "      <td>http://g28.ycxafz.biz/</td>\n",
       "      <td>2017-01-01 06:45:00</td>\n",
       "      <td>g28.ycxafz.biz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4717281</td>\n",
       "      <td>http://sistemas.miranda.gob.ve/1/Sign%20on/add...</td>\n",
       "      <td>by cleanmx</td>\n",
       "      <td>VALID PHISH</td>\n",
       "      <td>Offline</td>\n",
       "      <td>http://sistemas.miranda.gob.ve/1/Sign%20on/</td>\n",
       "      <td>2017-01-01 05:46:00</td>\n",
       "      <td>sistemas.miranda.gob.ve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4717246</td>\n",
       "      <td>http://sheehydaringproject.com/PDFILES/added o...</td>\n",
       "      <td>by cleanmx</td>\n",
       "      <td>VALID PHISH</td>\n",
       "      <td>Offline</td>\n",
       "      <td>http://sheehydaringproject.com/PDFILES/</td>\n",
       "      <td>2017-01-01 04:15:00</td>\n",
       "      <td>sheehydaringproject.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4717232</td>\n",
       "      <td>http://monar-kielce.pl/templates/beez/gdoc/ind...</td>\n",
       "      <td>by cleanmx</td>\n",
       "      <td>VALID PHISH</td>\n",
       "      <td>Offline</td>\n",
       "      <td>http://monar-kielce.pl/templates/beez/gdoc/ind...</td>\n",
       "      <td>2017-01-01 03:15:00</td>\n",
       "      <td>monar-kielce.pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4717222</td>\n",
       "      <td>http://www.w-reia.com/bremer/new.php?cmd=login...</td>\n",
       "      <td>by cleanmx</td>\n",
       "      <td>VALID PHISH</td>\n",
       "      <td>Offline</td>\n",
       "      <td>http://www.w-reia.com/bremer/new.php?cmd=login...</td>\n",
       "      <td>2017-01-01 02:46:00</td>\n",
       "      <td>www.w-reia.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101315</th>\n",
       "      <td>5407512</td>\n",
       "      <td>http://posari.com/Goody/Yahoo/home/index.phpad...</td>\n",
       "      <td>by cleanmx</td>\n",
       "      <td>VALID PHISH</td>\n",
       "      <td>Offline</td>\n",
       "      <td>http://posari.com/Goody/Yahoo/home/index.php</td>\n",
       "      <td>2018-01-01 05:42:00</td>\n",
       "      <td>posari.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101316</th>\n",
       "      <td>5407505</td>\n",
       "      <td>http://abrazzak.com/login.php?cmd=login_submit...</td>\n",
       "      <td>by cleanmx</td>\n",
       "      <td>VALID PHISH</td>\n",
       "      <td>ONLINE</td>\n",
       "      <td>http://abrazzak.com/login.php?cmd=login_submit...</td>\n",
       "      <td>2018-01-01 05:41:00</td>\n",
       "      <td>abrazzak.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101317</th>\n",
       "      <td>5407493</td>\n",
       "      <td>http://khanqahzakariya.lk/wpadmin/ex2017/login...</td>\n",
       "      <td>by cleanmx</td>\n",
       "      <td>VALID PHISH</td>\n",
       "      <td>ONLINE</td>\n",
       "      <td>http://khanqahzakariya.lk/wpadmin/ex2017/login...</td>\n",
       "      <td>2018-01-01 05:41:00</td>\n",
       "      <td>khanqahzakariya.lk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101318</th>\n",
       "      <td>5407490</td>\n",
       "      <td>http://pegesunblocking.000webhostapp.com/bayar...</td>\n",
       "      <td>by cleanmx</td>\n",
       "      <td>VALID PHISH</td>\n",
       "      <td>Offline</td>\n",
       "      <td>http://pegesunblocking.000webhostapp.com/bayar...</td>\n",
       "      <td>2018-01-01 05:40:00</td>\n",
       "      <td>pegesunblocking.000webhostapp.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101319</th>\n",
       "      <td>5407489</td>\n",
       "      <td>http://pegesunblocking.000webhostapp.com/bayar...</td>\n",
       "      <td>by cleanmx</td>\n",
       "      <td>VALID PHISH</td>\n",
       "      <td>Offline</td>\n",
       "      <td>http://pegesunblocking.000webhostapp.com/bayar...</td>\n",
       "      <td>2018-01-01 05:40:00</td>\n",
       "      <td>pegesunblocking.000webhostapp.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101320 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                          Phish URL  \\\n",
       "0       4717300  http://g28.ycxafz.biz/added on Jan 1st 2017 6:...   \n",
       "1       4717281  http://sistemas.miranda.gob.ve/1/Sign%20on/add...   \n",
       "2       4717246  http://sheehydaringproject.com/PDFILES/added o...   \n",
       "3       4717232  http://monar-kielce.pl/templates/beez/gdoc/ind...   \n",
       "4       4717222  http://www.w-reia.com/bremer/new.php?cmd=login...   \n",
       "...         ...                                                ...   \n",
       "101315  5407512  http://posari.com/Goody/Yahoo/home/index.phpad...   \n",
       "101316  5407505  http://abrazzak.com/login.php?cmd=login_submit...   \n",
       "101317  5407493  http://khanqahzakariya.lk/wpadmin/ex2017/login...   \n",
       "101318  5407490  http://pegesunblocking.000webhostapp.com/bayar...   \n",
       "101319  5407489  http://pegesunblocking.000webhostapp.com/bayar...   \n",
       "\n",
       "         Submitted       Valid?  Online?  \\\n",
       "0       by cleanmx  VALID PHISH  Offline   \n",
       "1       by cleanmx  VALID PHISH  Offline   \n",
       "2       by cleanmx  VALID PHISH  Offline   \n",
       "3       by cleanmx  VALID PHISH  Offline   \n",
       "4       by cleanmx  VALID PHISH  Offline   \n",
       "...            ...          ...      ...   \n",
       "101315  by cleanmx  VALID PHISH  Offline   \n",
       "101316  by cleanmx  VALID PHISH   ONLINE   \n",
       "101317  by cleanmx  VALID PHISH   ONLINE   \n",
       "101318  by cleanmx  VALID PHISH  Offline   \n",
       "101319  by cleanmx  VALID PHISH  Offline   \n",
       "\n",
       "                                                      url  \\\n",
       "0                                  http://g28.ycxafz.biz/   \n",
       "1             http://sistemas.miranda.gob.ve/1/Sign%20on/   \n",
       "2                 http://sheehydaringproject.com/PDFILES/   \n",
       "3       http://monar-kielce.pl/templates/beez/gdoc/ind...   \n",
       "4       http://www.w-reia.com/bremer/new.php?cmd=login...   \n",
       "...                                                   ...   \n",
       "101315       http://posari.com/Goody/Yahoo/home/index.php   \n",
       "101316  http://abrazzak.com/login.php?cmd=login_submit...   \n",
       "101317  http://khanqahzakariya.lk/wpadmin/ex2017/login...   \n",
       "101318  http://pegesunblocking.000webhostapp.com/bayar...   \n",
       "101319  http://pegesunblocking.000webhostapp.com/bayar...   \n",
       "\n",
       "                       date                             domain  \n",
       "0       2017-01-01 06:45:00                     g28.ycxafz.biz  \n",
       "1       2017-01-01 05:46:00            sistemas.miranda.gob.ve  \n",
       "2       2017-01-01 04:15:00            sheehydaringproject.com  \n",
       "3       2017-01-01 03:15:00                    monar-kielce.pl  \n",
       "4       2017-01-01 02:46:00                     www.w-reia.com  \n",
       "...                     ...                                ...  \n",
       "101315  2018-01-01 05:42:00                         posari.com  \n",
       "101316  2018-01-01 05:41:00                       abrazzak.com  \n",
       "101317  2018-01-01 05:41:00                 khanqahzakariya.lk  \n",
       "101318  2018-01-01 05:40:00  pegesunblocking.000webhostapp.com  \n",
       "101319  2018-01-01 05:40:00  pegesunblocking.000webhostapp.com  \n",
       "\n",
       "[101320 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "NGRAMS = 2\n",
    "FEATURE_LEN = 128\n",
    "EPOCHS = 15\n",
    "SAMPLES = 50000\n",
    "\n",
    "df = pd.read_csv('../train-test/data/phishtank_2017.csv.bz2')\n",
    "df.dropna(subset=['domain'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Phish URL</th>\n",
       "      <th>Submitted</th>\n",
       "      <th>Valid?</th>\n",
       "      <th>Online?</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4717300</td>\n",
       "      <td>http://g28.ycxafz.biz/added on Jan 1st 2017 6:...</td>\n",
       "      <td>by cleanmx</td>\n",
       "      <td>VALID PHISH</td>\n",
       "      <td>Offline</td>\n",
       "      <td>http://g28.ycxafz.biz/</td>\n",
       "      <td>2017-01-01 06:45:00</td>\n",
       "      <td>g28.ycxafz.biz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4717281</td>\n",
       "      <td>http://sistemas.miranda.gob.ve/1/Sign%20on/add...</td>\n",
       "      <td>by cleanmx</td>\n",
       "      <td>VALID PHISH</td>\n",
       "      <td>Offline</td>\n",
       "      <td>http://sistemas.miranda.gob.ve/1/Sign%20on/</td>\n",
       "      <td>2017-01-01 05:46:00</td>\n",
       "      <td>sistemas.miranda.gob.ve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4717246</td>\n",
       "      <td>http://sheehydaringproject.com/PDFILES/added o...</td>\n",
       "      <td>by cleanmx</td>\n",
       "      <td>VALID PHISH</td>\n",
       "      <td>Offline</td>\n",
       "      <td>http://sheehydaringproject.com/PDFILES/</td>\n",
       "      <td>2017-01-01 04:15:00</td>\n",
       "      <td>sheehydaringproject.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4717232</td>\n",
       "      <td>http://monar-kielce.pl/templates/beez/gdoc/ind...</td>\n",
       "      <td>by cleanmx</td>\n",
       "      <td>VALID PHISH</td>\n",
       "      <td>Offline</td>\n",
       "      <td>http://monar-kielce.pl/templates/beez/gdoc/ind...</td>\n",
       "      <td>2017-01-01 03:15:00</td>\n",
       "      <td>monar-kielce.pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4717222</td>\n",
       "      <td>http://www.w-reia.com/bremer/new.php?cmd=login...</td>\n",
       "      <td>by cleanmx</td>\n",
       "      <td>VALID PHISH</td>\n",
       "      <td>Offline</td>\n",
       "      <td>http://www.w-reia.com/bremer/new.php?cmd=login...</td>\n",
       "      <td>2017-01-01 02:46:00</td>\n",
       "      <td>www.w-reia.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101289</th>\n",
       "      <td>5407454</td>\n",
       "      <td>http://online-banking.mobile.go.mambanetworkso...</td>\n",
       "      <td>by cleanmx</td>\n",
       "      <td>VALID PHISH</td>\n",
       "      <td>Offline</td>\n",
       "      <td>http://online-banking.mobile.go.mambanetworkso...</td>\n",
       "      <td>2018-01-01 04:41:00</td>\n",
       "      <td>online-banking.mobile.go.mambanetworksolutions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101291</th>\n",
       "      <td>5407450</td>\n",
       "      <td>http://www.royalbankpacific.com/wp-admin/maint...</td>\n",
       "      <td>by cleanmx</td>\n",
       "      <td>VALID PHISH</td>\n",
       "      <td>Offline</td>\n",
       "      <td>http://www.royalbankpacific.com/wp-admin/maint...</td>\n",
       "      <td>2018-01-01 04:40:00</td>\n",
       "      <td>www.royalbankpacific.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101293</th>\n",
       "      <td>5407446</td>\n",
       "      <td>http://healthyidealroutine.com/fl/87fb6e7a8551...</td>\n",
       "      <td>by cleanmx</td>\n",
       "      <td>VALID PHISH</td>\n",
       "      <td>Offline</td>\n",
       "      <td>http://healthyidealroutine.com/fl/87fb6e7a8551...</td>\n",
       "      <td>2018-01-01 04:40:00</td>\n",
       "      <td>healthyidealroutine.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101300</th>\n",
       "      <td>5407544</td>\n",
       "      <td>http://camplakefire.com.au/include/chase-onlin...</td>\n",
       "      <td>by cleanmx</td>\n",
       "      <td>VALID PHISH</td>\n",
       "      <td>Offline</td>\n",
       "      <td>http://camplakefire.com.au/include/chase-onlin...</td>\n",
       "      <td>2018-01-01 07:10:00</td>\n",
       "      <td>camplakefire.com.au</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101301</th>\n",
       "      <td>5407543</td>\n",
       "      <td>http://assemblgroup.com/ww/8eef918ed75a259d0e3...</td>\n",
       "      <td>by cleanmx</td>\n",
       "      <td>VALID PHISH</td>\n",
       "      <td>Offline</td>\n",
       "      <td>http://assemblgroup.com/ww/8eef918ed75a259d0e3...</td>\n",
       "      <td>2018-01-01 07:10:00</td>\n",
       "      <td>assemblgroup.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56517 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                          Phish URL  \\\n",
       "0       4717300  http://g28.ycxafz.biz/added on Jan 1st 2017 6:...   \n",
       "1       4717281  http://sistemas.miranda.gob.ve/1/Sign%20on/add...   \n",
       "2       4717246  http://sheehydaringproject.com/PDFILES/added o...   \n",
       "3       4717232  http://monar-kielce.pl/templates/beez/gdoc/ind...   \n",
       "4       4717222  http://www.w-reia.com/bremer/new.php?cmd=login...   \n",
       "...         ...                                                ...   \n",
       "101289  5407454  http://online-banking.mobile.go.mambanetworkso...   \n",
       "101291  5407450  http://www.royalbankpacific.com/wp-admin/maint...   \n",
       "101293  5407446  http://healthyidealroutine.com/fl/87fb6e7a8551...   \n",
       "101300  5407544  http://camplakefire.com.au/include/chase-onlin...   \n",
       "101301  5407543  http://assemblgroup.com/ww/8eef918ed75a259d0e3...   \n",
       "\n",
       "         Submitted       Valid?  Online?  \\\n",
       "0       by cleanmx  VALID PHISH  Offline   \n",
       "1       by cleanmx  VALID PHISH  Offline   \n",
       "2       by cleanmx  VALID PHISH  Offline   \n",
       "3       by cleanmx  VALID PHISH  Offline   \n",
       "4       by cleanmx  VALID PHISH  Offline   \n",
       "...            ...          ...      ...   \n",
       "101289  by cleanmx  VALID PHISH  Offline   \n",
       "101291  by cleanmx  VALID PHISH  Offline   \n",
       "101293  by cleanmx  VALID PHISH  Offline   \n",
       "101300  by cleanmx  VALID PHISH  Offline   \n",
       "101301  by cleanmx  VALID PHISH  Offline   \n",
       "\n",
       "                                                      url  \\\n",
       "0                                  http://g28.ycxafz.biz/   \n",
       "1             http://sistemas.miranda.gob.ve/1/Sign%20on/   \n",
       "2                 http://sheehydaringproject.com/PDFILES/   \n",
       "3       http://monar-kielce.pl/templates/beez/gdoc/ind...   \n",
       "4       http://www.w-reia.com/bremer/new.php?cmd=login...   \n",
       "...                                                   ...   \n",
       "101289  http://online-banking.mobile.go.mambanetworkso...   \n",
       "101291  http://www.royalbankpacific.com/wp-admin/maint...   \n",
       "101293  http://healthyidealroutine.com/fl/87fb6e7a8551...   \n",
       "101300  http://camplakefire.com.au/include/chase-onlin...   \n",
       "101301  http://assemblgroup.com/ww/8eef918ed75a259d0e3...   \n",
       "\n",
       "                       date                                             domain  \n",
       "0       2017-01-01 06:45:00                                     g28.ycxafz.biz  \n",
       "1       2017-01-01 05:46:00                            sistemas.miranda.gob.ve  \n",
       "2       2017-01-01 04:15:00                            sheehydaringproject.com  \n",
       "3       2017-01-01 03:15:00                                    monar-kielce.pl  \n",
       "4       2017-01-01 02:46:00                                     www.w-reia.com  \n",
       "...                     ...                                                ...  \n",
       "101289  2018-01-01 04:41:00  online-banking.mobile.go.mambanetworksolutions...  \n",
       "101291  2018-01-01 04:40:00                           www.royalbankpacific.com  \n",
       "101293  2018-01-01 04:40:00                            healthyidealroutine.com  \n",
       "101300  2018-01-01 07:10:00                                camplakefire.com.au  \n",
       "101301  2018-01-01 07:10:00                                   assemblgroup.com  \n",
       "\n",
       "[56517 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = df.drop_duplicates('domain')\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sdf.groupby('target').agg({'domain': 'count'})\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>youtube.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>facebook.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>baidu.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>wikipedia.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>999996</td>\n",
       "      <td>liberty-shopping.us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>999997</td>\n",
       "      <td>uazz.pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>999998</td>\n",
       "      <td>waltonsun.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>999999</td>\n",
       "      <td>aspvv.it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>1000000</td>\n",
       "      <td>wetterklima.de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rank               domain\n",
       "0             1           google.com\n",
       "1             2          youtube.com\n",
       "2             3         facebook.com\n",
       "3             4            baidu.com\n",
       "4             5        wikipedia.org\n",
       "...         ...                  ...\n",
       "999995   999996  liberty-shopping.us\n",
       "999996   999997              uazz.pl\n",
       "999997   999998        waltonsun.com\n",
       "999998   999999             aspvv.it\n",
       "999999  1000000       wetterklima.de\n",
       "\n",
       "[1000000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adf = pd.read_csv('../train-test/data/top-1m.csv.zip', header=None)\n",
    "adf.columns = ['rank', 'domain']\n",
    "adf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf = adf[['domain']].head(SAMPLES)\n",
    "pdf = sdf[['domain']].sample(SAMPLES, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>phishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google.com</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>youtube.com</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook.com</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baidu.com</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wikipedia.org</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25900</th>\n",
       "      <td>unlocklivevideofacebook.lifecares.info</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28584</th>\n",
       "      <td>co.digital</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86481</th>\n",
       "      <td>alexggilbert.com</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13097</th>\n",
       "      <td>www.union.gr</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8418</th>\n",
       "      <td>simunpetshop.co.id</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       domain  phishing\n",
       "0                                  google.com     False\n",
       "1                                 youtube.com     False\n",
       "2                                facebook.com     False\n",
       "3                                   baidu.com     False\n",
       "4                               wikipedia.org     False\n",
       "...                                       ...       ...\n",
       "25900  unlocklivevideofacebook.lifecares.info      True\n",
       "28584                              co.digital      True\n",
       "86481                        alexggilbert.com      True\n",
       "13097                            www.union.gr      True\n",
       "8418                       simunpetshop.co.id      True\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldf['phishing'] = False\n",
    "pdf['phishing'] = True\n",
    "tdf = pd.concat([ldf, pdf])\n",
    "tdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words = 1453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([list([129, 105, 134, 311, 39, 8, 0, 0, 0]),\n",
       "       list([288, 68, 141, 166, 213, 128, 8, 0, 0, 0]),\n",
       "       list([188, 43, 66, 58, 161, 105, 218, 142, 0, 0, 0]), ...,\n",
       "       list([16, 39, 219, 894, 471, 152, 77, 376, 128, 3, 76, 25, 0, 0, 0]),\n",
       "       list([1, 1, 15, 146, 83, 102, 60, 9, 36, 154, 182]),\n",
       "       list([65, 149, 290, 83, 367, 121, 13, 137, 133, 38, 157, 74, 0, 0, 28, 46, 103])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if True:\n",
    "    # build n-gram list\n",
    "    vect = CountVectorizer(analyzer='char', max_df=0.3, min_df=3, ngram_range=(NGRAMS, NGRAMS), lowercase=False) \n",
    "    #vect = CountVectorizer(analyzer='char', ngram_range=(NGRAMS, NGRAMS), lowercase=False) \n",
    "    a = vect.fit_transform(tdf.domain)\n",
    "    vocab = vect.vocabulary_\n",
    "\n",
    "    # sort n-gram by freq (highest -> lowest)\n",
    "    words = []\n",
    "    for b in vocab:\n",
    "        c = vocab[b]\n",
    "        #print(b, c, a[:, c].sum())\n",
    "        words.append((a[:, c].sum(), b))\n",
    "        #break\n",
    "    words = sorted(words, reverse=True)\n",
    "    words_list = [w[1] for w in words]\n",
    "    num_words = len(words_list)\n",
    "    print(\"num_words = %d\" % num_words)\n",
    "\n",
    "\n",
    "    def find_ngrams(text, n):\n",
    "        a = zip(*[text[i:] for i in range(n)])\n",
    "        wi = []\n",
    "        for i in a:\n",
    "            w = ''.join(i)\n",
    "            try:\n",
    "                idx = words_list.index(w)\n",
    "            except:\n",
    "                idx = 0\n",
    "            wi.append(idx)\n",
    "        return wi\n",
    "\n",
    "    # build X from index of n-gram sequence\n",
    "    X = np.array(tdf.domain.apply(lambda c: find_ngrams(c, NGRAMS)))\n",
    "else:\n",
    "    data = tdf.domain.str.cat()\n",
    "    chars = list(set(data))\n",
    "    data_size, vocab_size = len(data), len(chars)\n",
    "    print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "    char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "    ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "    num_words = vocab_size\n",
    "    X = np.array(tdf.domain.apply(lambda c: [char_to_ix[a] for a in c]))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max feature len = 62, Avg. feature len = 16\n"
     ]
    }
   ],
   "source": [
    "# check max/avg feature\n",
    "X_len = []\n",
    "for x in X:\n",
    "    X_len.append(len(x))\n",
    "\n",
    "max_feature_len = max(X_len)\n",
    "avg_feature_len = int(np.mean(X_len))\n",
    "\n",
    "print(\"Max feature len = %d, Avg. feature len = %d\" % (max_feature_len, avg_feature_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(tdf.phishing.astype('category').cat.codes)\n",
    "\n",
    "# Split train and test dataset\n",
    "X_train,  X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 train sequences\n",
      "20000 test sequences\n",
      "Pad sequences (samples x time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (80000, 128)\n",
      "X_test shape: (20000, 128)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.models import load_model\n",
    "\n",
    "max_features = num_words # 20000\n",
    "feature_len = FEATURE_LEN # avg_feature_len # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=feature_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=feature_len)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 128, 32)           46496     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               82432     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 129,057\n",
      "Trainable params: 129,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, 32, input_length=feature_len))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv37/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72000 samples, validate on 8000 samples\n",
      "Epoch 1/15\n",
      "72000/72000 [==============================] - 354s 5ms/step - loss: 0.4048 - accuracy: 0.8081 - val_loss: 0.3645 - val_accuracy: 0.8347\n",
      "Epoch 2/15\n",
      "72000/72000 [==============================] - 387s 5ms/step - loss: 0.3719 - accuracy: 0.8258 - val_loss: 0.3622 - val_accuracy: 0.8347\n",
      "Epoch 3/15\n",
      "72000/72000 [==============================] - 519s 7ms/step - loss: 0.3630 - accuracy: 0.8298 - val_loss: 0.3593 - val_accuracy: 0.8326\n",
      "Epoch 4/15\n",
      "72000/72000 [==============================] - 509s 7ms/step - loss: 0.3554 - accuracy: 0.8343 - val_loss: 0.3480 - val_accuracy: 0.8393\n",
      "Epoch 5/15\n",
      "72000/72000 [==============================] - 514s 7ms/step - loss: 0.3475 - accuracy: 0.8380 - val_loss: 0.3478 - val_accuracy: 0.8380\n",
      "Epoch 6/15\n",
      "72000/72000 [==============================] - 515s 7ms/step - loss: 0.3423 - accuracy: 0.8408 - val_loss: 0.3433 - val_accuracy: 0.8403\n",
      "Epoch 7/15\n",
      "72000/72000 [==============================] - 512s 7ms/step - loss: 0.3369 - accuracy: 0.8440 - val_loss: 0.3437 - val_accuracy: 0.8403\n",
      "Epoch 8/15\n",
      "72000/72000 [==============================] - 512s 7ms/step - loss: 0.3328 - accuracy: 0.8453 - val_loss: 0.3446 - val_accuracy: 0.8429\n",
      "Epoch 9/15\n",
      "72000/72000 [==============================] - 509s 7ms/step - loss: 0.3342 - accuracy: 0.8443 - val_loss: 0.3432 - val_accuracy: 0.8415\n",
      "Epoch 10/15\n",
      "72000/72000 [==============================] - 507s 7ms/step - loss: 0.3262 - accuracy: 0.8492 - val_loss: 0.3458 - val_accuracy: 0.8416\n",
      "Epoch 11/15\n",
      "72000/72000 [==============================] - 511s 7ms/step - loss: 0.3213 - accuracy: 0.8515 - val_loss: 0.3450 - val_accuracy: 0.8418\n",
      "Epoch 12/15\n",
      "72000/72000 [==============================] - 490s 7ms/step - loss: 0.3173 - accuracy: 0.8537 - val_loss: 0.3463 - val_accuracy: 0.8416\n",
      "Epoch 13/15\n",
      "72000/72000 [==============================] - 375s 5ms/step - loss: 0.3138 - accuracy: 0.8557 - val_loss: 0.3529 - val_accuracy: 0.8418\n",
      "Epoch 14/15\n",
      "72000/72000 [==============================] - 382s 5ms/step - loss: 0.3107 - accuracy: 0.8572 - val_loss: 0.3469 - val_accuracy: 0.8425\n",
      "Epoch 15/15\n",
      "72000/72000 [==============================] - 376s 5ms/step - loss: 0.3063 - accuracy: 0.8601 - val_loss: 0.3504 - val_accuracy: 0.8443\n",
      "20000/20000 [==============================] - 31s 2ms/step\n",
      "Test score: 0.36727409273386\n",
      "Test accuracy: 0.8356500267982483\n"
     ]
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=EPOCHS,\n",
    "          validation_split=0.1, verbose=1)\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=batch_size, verbose=1)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 31s 2ms/step\n",
      "20000/20000 [==============================] - 33s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test, verbose=1)\n",
    "y_probs = model.predict_proba(X_test, verbose=1) # to predict probability\n",
    "target_names = list(tdf.phishing.astype('category').cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.89      0.84     10000\n",
      "        True       0.88      0.78      0.83     10000\n",
      "\n",
      "    accuracy                           0.84     20000\n",
      "   macro avg       0.84      0.84      0.84     20000\n",
      "weighted avg       0.84      0.84      0.84     20000\n",
      "\n",
      "[[8926 1074]\n",
      " [2213 7787]]\n"
     ]
    }
   ],
   "source": [
    "target_names = [str(t) for t in target_names]\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(confusion_matrix(y_test, y_pred))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the model with 100 trees\n",
    "rf_model = RandomForestClassifier(n_estimators=100, \n",
    "                                  bootstrap = True,\n",
    "                                  max_features = 'sqrt')\n",
    "# Fit on training data\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual class predictions\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "# Probabilities for each class\n",
    "rf_y_probs = rf_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = rf_y_probs\n",
    "target_names = list(tdf.phishing.astype('category').cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      0.87      0.83     10000\n",
      "        True       0.86      0.76      0.80     10000\n",
      "\n",
      "    accuracy                           0.82     20000\n",
      "   macro avg       0.82      0.82      0.81     20000\n",
      "weighted avg       0.82      0.82      0.81     20000\n",
      "\n",
      "[[8734 1266]\n",
      " [2422 7578]]\n"
     ]
    }
   ],
   "source": [
    "target_names = [str(t) for t in target_names]\n",
    "print(classification_report(y_test, rf_y_pred, target_names=target_names))\n",
    "print(confusion_matrix(y_test, rf_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svc_model = svm.SVC(probability=True)\n",
    "# Fit on training data\n",
    "svc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual class predictions\n",
    "svc_y_pred = svc_model.predict(X_test)\n",
    "# Probabilities for each class\n",
    "svc_y_probs = svc_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = svc_y_probs\n",
    "target_names = list(tdf.phishing.astype('category').cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.84      0.77     10000\n",
      "        True       0.80      0.67      0.73     10000\n",
      "\n",
      "    accuracy                           0.76     20000\n",
      "   macro avg       0.76      0.76      0.75     20000\n",
      "weighted avg       0.76      0.76      0.75     20000\n",
      "\n",
      "[[8926 1074]\n",
      " [2213 7787]]\n"
     ]
    }
   ],
   "source": [
    "target_names = [str(t) for t in target_names]\n",
    "print(classification_report(y_test, svc_y_pred, target_names=target_names))\n",
    "print(confusion_matrix(y_test, y_pred))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "lstm_fpr, lstm_tpr, lstm_thresholds = roc_curve ( y_test , y_probs)\n",
    "rf_fpr, rf_tpr, rf_thresholds = roc_curve ( y_test , rf_y_probs)\n",
    "svc_fpr, svc_tpr, svc_thresholds = roc_curve ( y_test , svc_y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.91192025, 0.8953730149999999, 0.8214482350000001)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_auc = roc_auc_score(y_test, y_probs)\n",
    "rf_auc = roc_auc_score(y_test, rf_y_probs)\n",
    "svc_auc = roc_auc_score(y_test, svc_y_probs)\n",
    "lstm_auc, rf_auc, svc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(12, 8))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(lstm_fpr, lstm_tpr, label='LSTM (area = {:.3f})'.format(lstm_auc))\n",
    "plt.plot(rf_fpr, rf_tpr, label='RF (area = {:.3f})'.format(rf_auc))\n",
    "plt.plot(svc_fpr, svc_tpr, label='SVC (area = {:.3f})'.format(svc_auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/phish_cat_lstm_2017.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.DataFrame(words_list, columns=['vocab'])\n",
    "words_df.to_csv('./models/phish_cat_vocab_2017.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(rf_model, open('./models/phish_cat_2017_rf.pickle', 'wb'))\n",
    "pickle.dump(svc_model, open('./models/phish_cat_2017_svm.pickle', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
